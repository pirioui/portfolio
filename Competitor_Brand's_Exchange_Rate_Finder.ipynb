{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfwohO6YAdR3",
        "outputId": "52c5197f-31be-4dc5-d7ea-1dfef247d4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-05 00:08:09: Ariyaya rate 5.17฿\n",
            "2023-10-05 00:08:09: Plmcargo rate 5.19฿\n",
            "2023-10-05 00:08:09: Weshopchina rate 5.31฿\n",
            "2023-10-05 00:08:09: Ydcargo rate 5.20฿\n",
            "2023-10-05 00:08:09: Uneedcargo rate 5.19฿\n",
            "2023-10-05 00:08:09: Jmfcargo rate 5.22฿\n",
            "2023-10-05 00:08:09: Ptcargo rate 5.150฿\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "local_timestamp = datetime.now()\n",
        "gmt7_tz = timezone(timedelta(hours=7))\n",
        "timestamp_gmt7 = local_timestamp.astimezone(gmt7_tz)\n",
        "formatted_timestamp = timestamp_gmt7.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "# Ariyaya\n",
        "url = \"https://ariyayapreorder.com/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "data0 = soup.find('span',{\"class\":\"brk-base-font-color pr-5 font__size-36\"})\n",
        "ariyaya_rate = data0.text.strip()\n",
        "\n",
        "# plm-cargo\n",
        "url1 = \"https://www.plm-cargo.com/\"\n",
        "response1 = requests.get(url1)\n",
        "soup1 = BeautifulSoup(response1.content, \"html.parser\")\n",
        "data1 = soup1.find('div',{\"class\":\"ant-col feature6-number-wrapper ant-col-xs-6 ant-col-md-6\"})\n",
        "plmcargo_rate = data1.text.replace(\"พรีออเดอร์\",\"\")\n",
        "\n",
        "# Weshopchina\n",
        "url2 = \"https://weshopchina.com/external/get_exchange_rate.php\"\n",
        "response2 = requests.get(url2)\n",
        "soup2 = BeautifulSoup(response2.content, \"html.parser\")\n",
        "weshopchina_rate = soup2\n",
        "\n",
        "# YD-Cargo\n",
        "url3 = \"https://www.yd-cargo.com/index.php\"\n",
        "response3 = requests.get(url3)\n",
        "soup3 = BeautifulSoup(response3.content, \"html.parser\")\n",
        "data3 = soup3.find('div',{\"class\":\"pricing-content\"})\n",
        "ydcargo_rate = data3.text.replace(\"พรีออเดอร์\",\"\").strip()\n",
        "\n",
        "# Uneedcargo\n",
        "url4 = \"https://www.uneedcargo.com/home?ref=600150e8868c2\"\n",
        "response4 = requests.get(url4)\n",
        "soup4 = BeautifulSoup(response4.content, \"html.parser\")\n",
        "data4 = soup4.find('div',{\"class\":\"rate-subheading\"})\n",
        "uneedcargo_rate = data4.text\n",
        "\n",
        "# JMFCargo\n",
        "url5 = \"https://jmfcargo.com/\"\n",
        "response5 = requests.get(url5)\n",
        "soup5 = BeautifulSoup(response5.content, \"html.parser\")\n",
        "data05 = soup5.find('span',{\"text-color-main tam-counter font-4_5rem\"})\n",
        "data5 = data05['data-count']\n",
        "jmfcargo_rate = data5\n",
        "\n",
        "# PTCargo\n",
        "url6 = 'https://www.ptcargomember.com/login_page.php'\n",
        "login_payload = {\n",
        "    'username': 'pirioui',\n",
        "    'password': 'ouioui'}\n",
        "session = requests.Session()\n",
        "responseo = session.post(url6, login_payload)\n",
        "new_url = 'https://www.ptcargomember.com/dashboard/index.php'\n",
        "timeout = 15\n",
        "start_time = time.time()\n",
        "time.sleep(1)\n",
        "response6 = session.get(new_url)\n",
        "soup6 = BeautifulSoup(response6.content, \"html.parser\")\n",
        "data06 = soup6.find('td',{\"class\":\"text-center\"})\n",
        "data6 = data06.text\n",
        "def remove_pattern(text):\n",
        "    pattern = r'\\s*\\([+-]?\\d+\\.\\d+\\)\\s*'\n",
        "    result = re.sub(pattern, '', data6)\n",
        "    return result\n",
        "data006 = remove_pattern(data6)\n",
        "ptcargo_rate = data006.strip()\n",
        "\n",
        "####\n",
        "\n",
        "rate_names = [\"ariyaya\", \"plmcargo\", \"weshopchina\", \"ydcargo\", \"uneedcargo\", \"jmfcargo\", \"ptcargo\"]\n",
        "all_data = '\\n'.join([f\"{formatted_timestamp}: {name.capitalize()} rate {globals()[f'{name}_rate']} ฿\" for name in rate_names])\n",
        "lastcall = all_data.replace(' ฿', '฿').replace('฿฿','฿')\n",
        "\n",
        "print(lastcall)\n",
        "cwd = os.getcwd()\n",
        "if not os.path.exists(os.path.join(cwd, \"CNY.exchange.rate.txt\")):\n",
        "        with open(os.path.join(cwd, \"CNY.exchange.rate.txt\"), \"w\") as f:\n",
        "            f.write(\"\")\n",
        "\n",
        "with open(os.path.join(cwd, \"CNY.exchange.rate.txt\"), \"a\") as f:\n",
        "    f.write(f\"{lastcall}\\n\")"
      ]
    }
  ]
}